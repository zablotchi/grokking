defaults:
  - dataset: mod_subtract_dataset
  - model: grokk_model
  - _self_

dataset:
  frac_train: 0.4
  p: 96

model:
  transformer_config:
    pre_norm: true

train:
  num_workers: 0
  bsize: 512
  lr: 1e-2
  lr_decay_patience: 50 # in units of eval set evaluations
  lr_decay_factor: 0.1
  min_lr: 1e-8 # point at which training terminates
  weight_decay: 0.0
  betas: [0.9, 0.98]
  warmup_steps: 10
  eval_every: 50
  eval_batches: 20
  loss_key: xent

wandb:
  use_wandb: true
  wandb_project: grokking
  wandb_entity: data-frugal-learning
  wandb_tags: [test]
